{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Load Data\n",
    "a=[\"date\",\"Appliances\",\"T1\",\"RH_1\",\"T2\",\"RH_2\",\"T3\",\"RH_3\",\"T4\",\"RH_4\",\"T5\",\"RH_5\",\"T6\",\"RH_6\",\"T7\",\"RH_7\",\"T8\",\"RH_8\",\"T9\",\"RH_9\",\"NSM\",\"T_out\",\"RH_out\",\"Windspeed\",\"Visibility\",\"rv1\",\"rv2\"]\n",
    "#load the datasets\n",
    "df = pd.read_csv(\"./dataframeResult/modifiedDataset.csv\",usecols=a)\n",
    "df[\"date1\"]=(df['date'].str.split(':').str[0])\n",
    "del a[0]\n",
    "table = pd.pivot_table(df,index=[\"date1\"],\n",
    "               values = a,\n",
    "               aggfunc=[np.sum],fill_value=0)\n",
    "\n",
    "\n",
    "y = np.array(table[(\"sum\",'Appliances')])\n",
    "del table[(\"sum\",\"Appliances\")]\n",
    "X = np.array(table.values.tolist())\n",
    "\n",
    "\n",
    "##boston=datasets.load_boston()\n",
    "##X,y=shuffle(boston.data,boston.target,random_state=13)\n",
    "##X=X.astype(np.float32)\n",
    "##offset=int(X.shape[0]*0.9)\n",
    "##X_train,y_train=X[:offset],y[:offset]\n",
    "##X_test,y_test=X[offset:],y[offset:]\n",
    "\n",
    "#Fit Regression Model\n",
    "\n",
    "params={'n_estimators':500,'max_depth':4,'min_samples_split':2,\n",
    "        'learning_rate':0.01}\n",
    "clf=ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "clf.fit(X,y)\n",
    "mse=mean_squared_error(y,clf.predict(X))\n",
    "print(\"MSE:%.4f\" % mse)\n",
    "\n",
    "#Plot Training Deviance\n",
    "\n",
    "# compute test set deviance\n",
    "test_score=np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "for i,y_pred in enumerate(clf.staged_predict(X)):\n",
    "    test_score[i]=clf.loss_(y,y_pred)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Deviance')\n",
    "##plt.plot(np.arange(params['n_estimators'])+1,clf.train_score_,'b-',\n",
    "##         label='Training Set Deviance')\n",
    "##plt.plot(np.arange(params['n_estimators'])+1, clf.train_score_,'b-',\n",
    "##         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators'])+1,test_score,'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')\n",
    "#plt.show()\n",
    "\n",
    "#Plot Feature Importance\n",
    "feature_importance=clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance=100.0*(feature_importance/feature_importance.max())\n",
    "sorted_idx=np.argsort(feature_importance)\n",
    "pos=np.arange(sorted_idx.shape[0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(pos,feature_importance[sorted_idx],align='center')\n",
    "plt.yticks(pos,table.columns.get_level_values(1))\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
