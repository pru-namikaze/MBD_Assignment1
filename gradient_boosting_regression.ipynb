{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "from matplotlib import pyplot as plot\n",
    "from pathlib import Path  \n",
    "import pandas as pandas\n",
    "import numpy as numpy\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>rv2</th>\n",
       "      <th>NSM</th>\n",
       "      <th>week_status</th>\n",
       "      <th>day_of_monday</th>\n",
       "      <th>day_of_tuesday</th>\n",
       "      <th>day_of_wednesday</th>\n",
       "      <th>day_of_thursday</th>\n",
       "      <th>day_of_friday</th>\n",
       "      <th>day_of_saturday</th>\n",
       "      <th>day_of_sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>61200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>...</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>61800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>62400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>...</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>63600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Appliances  lights     T1       RH_1    T2       RH_2     T3       RH_3  \\\n",
       "0          60      30  19.89  47.596667  19.2  44.790000  19.79  44.730000   \n",
       "1          60      30  19.89  46.693333  19.2  44.722500  19.79  44.790000   \n",
       "2          50      30  19.89  46.300000  19.2  44.626667  19.79  44.933333   \n",
       "3          50      40  19.89  46.066667  19.2  44.590000  19.79  45.000000   \n",
       "4          60      40  19.89  46.333333  19.2  44.530000  19.79  45.000000   \n",
       "\n",
       "          T4       RH_4  ...        rv2      NSM  week_status  day_of_monday  \\\n",
       "0  19.000000  45.566667  ...  13.275433  61200.0            1           True   \n",
       "1  19.000000  45.992500  ...  18.606195  61800.0            1           True   \n",
       "2  18.926667  45.890000  ...  28.642668  62400.0            1           True   \n",
       "3  18.890000  45.723333  ...  45.410389  63000.0            1           True   \n",
       "4  18.890000  45.530000  ...  10.084097  63600.0            1           True   \n",
       "\n",
       "   day_of_tuesday  day_of_wednesday  day_of_thursday  day_of_friday  \\\n",
       "0           False             False            False          False   \n",
       "1           False             False            False          False   \n",
       "2           False             False            False          False   \n",
       "3           False             False            False          False   \n",
       "4           False             False            False          False   \n",
       "\n",
       "   day_of_saturday  day_of_sunday  \n",
       "0            False          False  \n",
       "1            False          False  \n",
       "2            False          False  \n",
       "3            False          False  \n",
       "4            False          False  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pandas.read_csv(\"dataset.csv\").dropna()\n",
    "dataframe[\"date\"] = pandas.to_datetime(dataframe['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "dataframe[\"NSM\"] = (dataframe[\"date\"] - pandas.to_datetime(dataframe['date'].dt.date, format='%Y-%m-%d')).dt.total_seconds()\n",
    "dataframe[\"week_status\"] = dataframe[\"date\"].apply(lambda date: 1 if(date.weekday() <= 4) else 0)\n",
    "dataframe[\"day_of_monday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 0)\n",
    "dataframe[\"day_of_tuesday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 1)\n",
    "dataframe[\"day_of_wednesday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 2)\n",
    "dataframe[\"day_of_thursday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 3)\n",
    "dataframe[\"day_of_friday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 4)\n",
    "dataframe[\"day_of_saturday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 5)\n",
    "dataframe[\"day_of_sunday\"] = dataframe[\"date\"].apply(lambda date: date.weekday() == 6)\n",
    "dataframe = dataframe.drop(\"date\", axis = 1).dropna()\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop(\"Appliances\", axis = 1)\n",
    "y = dataframe[\"Appliances\"]\n",
    "TEST_SIZE_RATIO = 0.20\n",
    "RANDOM_STATE_SEED = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE_RATIO, random_state=RANDOM_STATE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Gradient Boosted Regression Model for MAX_DEPTH: 1\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       10221.7201            6.58m\n",
      "         2       10085.5847            6.40m\n",
      "         3        9975.3051            6.32m\n",
      "         4        9885.1927            6.30m\n",
      "         5        9811.6228            6.29m\n",
      "         6        9749.9519            6.23m\n",
      "         7        9692.3731            6.24m\n",
      "         8        9644.7444            6.20m\n",
      "         9        9599.6174            6.17m\n",
      "        10        9560.2494            6.14m\n",
      "        20        9263.6210            6.15m\n",
      "        30        9090.3992            6.11m\n",
      "        40        8972.4026            6.07m\n",
      "        50        8886.4634            6.08m\n",
      "        60        8816.0895            6.10m\n",
      "        70        8758.4507            6.13m\n",
      "        80        8709.0516            6.12m\n",
      "        90        8665.1536            6.09m\n",
      "       100        8625.3686            6.09m\n",
      "       200        8343.2612            5.99m\n",
      "       300        8162.7696            5.96m\n",
      "       400        8027.6447            5.91m\n",
      "       500        7920.4187            5.87m\n",
      "       600        7831.8601            5.78m\n",
      "       700        7756.8986            5.69m\n",
      "       800        7691.5057            5.61m\n",
      "       900        7633.7127            5.53m\n",
      "      1000        7582.1259            5.46m\n"
     ]
    }
   ],
   "source": [
    "GBR_metrics_dataset_PATH = Path(\"./GBR_metrics_dataset.csv\")\n",
    "if not (GBR_metrics_dataset_PATH.exists() and GBR_metrics_dataset_PATH.is_file()):\n",
    "    N_ESTIMATORS = 10_000\n",
    "    MAX_DEPTH_SET = [1, 2, 3]\n",
    "    performance = {}\n",
    "    for max_depth_iterator in MAX_DEPTH_SET:\n",
    "        print(\"\\nTraining Gradient Boosted Regression Model for MAX_DEPTH: %d\" %max_depth_iterator)\n",
    "        # Applying Gradient Boosting Regression model to the dataset.\n",
    "        # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "        gradient_boosting_regressor = GradientBoostingRegressor(n_estimators = N_ESTIMATORS, max_depth = max_depth_iterator, verbose = 1)\n",
    "        gradient_boosting_regressor.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate the metrics for the model.\n",
    "        # Reference: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "        performance[max_depth_iterator] = {}\n",
    "        for ilteration, y_pred in enumerate(gradient_boosting_regressor.staged_predict(X)):\n",
    "            performance[max_depth_iterator][ilteration + 1] = {\n",
    "                \"training_loss\": gradient_boosting_regressor.loss_(y, y_pred),\n",
    "                \"root_mean_square_error\": mean_squared_error(y, y_pred, squared=False),\n",
    "                \"r2_score\": r2_score(y, y_pred),\n",
    "                \"mean_absolute_error\": mean_absolute_error(y, y_pred),\n",
    "                \"mean_absolute_percentage_error\": mean_absolute_percentage_error(y, y_pred)\n",
    "            }\n",
    "    \n",
    "    # Save the calculated metrics of the Gradient Boosting Regression Model into the csv.\n",
    "    csv_string = \"\\\"max_depth\\\",\\\"iteration\\\",\\\"training_loss\\\",\\\"root_mean_square_error\\\",\\\"r2_score\\\",\\\"mean_absolute_error\\\",\\\"mean_absolute_percentage_error\\\"\"\n",
    "    for depth in performance.keys():\n",
    "        for iteration in numpy.arange(1, len(performance[depth]) + 1):\n",
    "            csv_string = csv_string + \"\\n\" + str(depth) + \",\" + str(iteration) + \",\" + str(performance[depth][iteration][\"training_loss\"]) + \",\" + str(performance[depth][iteration][\"root_mean_square_error\"]) + \",\" + str(performance[depth][iteration][\"r2_score\"]) + \",\" + str(performance[depth][iteration][\"mean_absolute_error\"]) + \",\" + str(performance[depth][iteration][\"mean_absolute_percentage_error\"])\n",
    "    gradient_boosted_graph_metrics_dataset = open(GBR_metrics_dataset_PATH.name, \"w\")\n",
    "    gradient_boosted_graph_metrics_dataset.write(csv_string)\n",
    "    gradient_boosted_graph_metrics_dataset.close()\n",
    "\n",
    "    # Save the importance of the feature w.r.t the most important feature and store the data into csv.\n",
    "    # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor.feature_importances_\n",
    "    GBR_RELEATIVE_FEATURE_IMPORTANCE_DATASET_PATH = Path(\"./GBR_releative_feature_importance_dataset.csv\")\n",
    "    feature_importance = gradient_boosting_regressor.feature_importances_\n",
    "    releative_feature_importance = (feature_importance / feature_importance.max()) * 100\n",
    "    sorted_indices=numpy.argsort(releative_feature_importance)\n",
    "    pandas.DataFrame(data = {\"feature_names\": numpy.array(feature_names)[sorted_indices], \"releative_feature_importance\": releative_feature_importance[sorted_indices], \"feature_importance\": feature_importance[sorted_indices]}).to_csv(GBR_RELEATIVE_FEATURE_IMPORTANCE_DATASET_PATH.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model's metrics using line graph subplots.\n",
    "# Reference: https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html\n",
    "gbr_metrics = pandas.read_csv(GBR_metrics_dataset_PATH.name)\n",
    "figure, (plot1, plot2, plot3, plot4, plot5) = plot.subplots(5)\n",
    "plot.tight_layout()\n",
    "\n",
    "plot1.set_title(\"Deviation vs Boosting Iteration for multiple max_depth\")\n",
    "plot1.set_xlabel('Boosting Iterations')\n",
    "plot1.set_ylabel('Deviance from Loss Funciton')\n",
    "for depth in gbr_metrics[\"max_depth\"].unique():\n",
    "    performance = gbr_metrics.where(gbr_metrics[\"max_depth\"] == depth).dropna()\n",
    "    plot1.plot(performance[\"iteration\"], performance[\"training_loss\"], label = \"max_depth: \"  + str(depth))\n",
    "plot1.legend(loc='upper right')\n",
    "\n",
    "plot2.set_title(\"Root Mean Square Error vs Boosting Iteration for multiple max_depth\")\n",
    "plot2.set_xlabel('Boosting Iterations')\n",
    "plot2.set_ylabel('Root Mean Square Error')\n",
    "for depth in gbr_metrics[\"max_depth\"].unique():\n",
    "    performance = gbr_metrics.where(gbr_metrics[\"max_depth\"] == depth).dropna()\n",
    "    plot2.plot(performance[\"iteration\"], performance[\"root_mean_square_error\"], label = \"max_depth: \"  + str(depth))\n",
    "plot2.legend(loc='upper right')\n",
    "\n",
    "plot3.set_title(\"R-square vs Boosting Iteration for multiple max_depth\")\n",
    "plot3.set_xlabel('Boosting Iterations')\n",
    "plot3.set_ylabel('R-square')\n",
    "for depth in gbr_metrics[\"max_depth\"].unique():\n",
    "    performance = gbr_metrics.where(gbr_metrics[\"max_depth\"] == depth).dropna()\n",
    "    plot3.plot(performance[\"iteration\"], performance[\"r2_score\"], label = \"max_depth: \"  + str(depth))\n",
    "plot3.legend(loc='upper right')\n",
    "\n",
    "plot4.set_title(\"Mean Absolute Error vs Boosting Iteration for multiple max_depth\")\n",
    "plot4.set_xlabel('Boosting Iterations')\n",
    "plot4.set_ylabel('Mean Absolute Error')\n",
    "for depth in gbr_metrics[\"max_depth\"].unique():\n",
    "    performance = gbr_metrics.where(gbr_metrics[\"max_depth\"] == depth).dropna()\n",
    "    plot4.plot(performance[\"iteration\"], performance[\"mean_absolute_error\"], label = \"max_depth: \"  + str(depth))\n",
    "plot4.legend(loc='upper right')\n",
    "\n",
    "plot5.set_title(\"Mean Absolute Percentage Error vs Boosting Iteration for multiple max_depth\")\n",
    "plot5.set_xlabel('Boosting Iterations')\n",
    "plot5.set_ylabel('Mean Absolute Percentage Error')\n",
    "for depth in gbr_metrics[\"max_depth\"].unique():\n",
    "    performance = gbr_metrics.where(gbr_metrics[\"max_depth\"] == depth).dropna()\n",
    "    plot5.plot(performance[\"iteration\"], performance[\"mean_absolute_percentage_error\"], label = \"max_depth: \"  + str(depth))\n",
    "plot5.legend(loc='upper right')\n",
    "\n",
    "figure.set_figheight(18)\n",
    "figure.set_figwidth(16)\n",
    "figure.suptitle(\"Metrics to select optimal parameters for GBR\")\n",
    "figure.savefig(\"GBR_metrics_vs_iteration_for_multiple_max_depth.png\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance of the model using bar graph subplots.\n",
    "# Reference: https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html\n",
    "gbr_metrics = pandas.read_csv(GBR_RELEATIVE_FEATURE_IMPORTANCE_DATASET_PATH.name)\n",
    "\n",
    "figure, (plot1, plot2) = plot.subplots(1, 2)\n",
    "\n",
    "plot1.barh(gbr_metrics[\"feature_names\"], gbr_metrics[\"releative_feature_importance\"], align=\"center\")\n",
    "plot1.set_xlabel('Relative Importance')\n",
    "plot1.set_title('Releative Feature Importance')\n",
    "\n",
    "plot2.barh(gbr_metrics[\"feature_names\"], gbr_metrics[\"feature_importance\"], align=\"center\")\n",
    "plot2.set_xlabel('Feature Importance')\n",
    "plot2.set_title('Feature Importance')\n",
    "\n",
    "figure.set_figheight(9)\n",
    "figure.set_figwidth(16)\n",
    "figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
