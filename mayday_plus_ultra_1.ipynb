{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "from matplotlib import pyplot as plot\n",
    "from pathlib import Path  \n",
    "import pandas as pandas\n",
    "import numpy as numpy\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"dataset.csv\").dropna()\n",
    "feature_names = [\"Appliances\",\"T1\",\"RH_1\",\"T2\",\"RH_2\",\"T3\",\"RH_3\",\"T4\",\"RH_4\",\"T5\",\"RH_5\",\"T6\",\"RH_6\",\"T7\",\"RH_7\",\"T8\",\"RH_8\",\"T9\",\"RH_9\",\"T_out\",\"Press_mm_hg\",\"RH_out\",\"Windspeed\",\"Visibility\",\"Tdewpoint\"]\n",
    "dataframe = dataframe[feature_names]\n",
    "\n",
    "X = dataframe.drop(\"Appliances\", axis = 1)\n",
    "y = dataframe[\"Appliances\"]\n",
    "TEST_SIZE_RATIO = (1 / 3)\n",
    "RANDOM_STATE_SEED = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE_RATIO, random_state=RANDOM_STATE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_metrics_dataset_PATH = Path(\"./GBR_metrics_dataset.csv\")\n",
    "if not (GBR_metrics_dataset_PATH.exists() and GBR_metrics_dataset_PATH.is_file()):\n",
    "    N_ESTIMATORS = 10_000\n",
    "    MAX_DEPTH_SET = [1, 2, 3]\n",
    "    performance = {}\n",
    "    for max_depth_iterator in MAX_DEPTH_SET:\n",
    "        print(\"\\nTraining Gradient Boosted Regression Model for MAX_DEPTH: %d\" %max_depth_iterator)\n",
    "        performance[max_depth_iterator] = [None] * N_ESTIMATORS\n",
    "        gradient_boosting_regressor = GradientBoostingRegressor(n_estimators = N_ESTIMATORS, max_depth = max_depth_iterator, verbose = 1)\n",
    "        gradient_boosting_regressor.fit(X_train, y_train)\n",
    "\n",
    "        performance[max_depth_iterator] = {}\n",
    "        for ilteration, y_pred in enumerate(gradient_boosting_regressor.staged_predict(X)):\n",
    "            performance[max_depth_iterator][ilteration + 1] = {\n",
    "                \"training_loss\": gradient_boosting_regressor.loss_(y, y_pred),\n",
    "                \"root_mean_square_error\": mean_squared_error(y, y_pred, squared=False),\n",
    "                \"r2_score\": r2_score(y, y_pred),\n",
    "                \"mean_absolute_error\": mean_absolute_error(y, y_pred),\n",
    "                \"mean_absolute_percentage_error\": mean_absolute_percentage_error(y, y_pred),\n",
    "            }\n",
    "    csv_string = \"\\\"max_depth\\\",\\\"iteration\\\",\\\"training_loss\\\",\\\"root_mean_square_error\\\",\\\"r2_score\\\",\\\"mean_absolute_error\\\",\\\"mean_absolute_percentage_error\\\"\"\n",
    "    for depth in performance.keys():\n",
    "        for iteration in numpy.arange(1, len(performance[depth]) + 1):\n",
    "            csv_string = csv_string + \"\\n\" + str(depth) + \",\" + str(iteration) + \",\" + str(performance[depth][iteration][\"training_loss\"]) + \",\" + str(performance[depth][iteration][\"root_mean_square_error\"]) + \",\" + str(performance[depth][iteration][\"r2_score\"]) + \",\" + str(performance[depth][iteration][\"mean_absolute_error\"]) + \",\" + str(performance[depth][iteration][\"mean_absolute_percentage_error\"])\n",
    "    gradient_boosted_graph_metrics_dataset = open(GBR_metrics_dataset_PATH.name, \"w\")\n",
    "    gradient_boosted_graph_metrics_dataset.write(csv_string)\n",
    "    gradient_boosted_graph_metrics_dataset.close()\n",
    "\n",
    "    GBR_RELEATIVE_FEATURE_IMPORTANCE_DATASET_PATH = Path(\"./GBR_releative_feature_importance_dataset.csv\")\n",
    "    feature_importance = gradient_boosting_regressor.feature_importances_\n",
    "    releative_feature_importance = (feature_importance / feature_importance.max()) * 100\n",
    "    sorted_indices=numpy.argsort(releative_feature_importance)\n",
    "    pandas.DataFrame(data = {\"feature_names\": numpy.array(feature_names)[sorted_indices], \"releative_feature_importance\": releative_feature_importance[sorted_indices], \"feature_importance\": feature_importance[sorted_indices]}).to_csv(GBR_RELEATIVE_FEATURE_IMPORTANCE_DATASET_PATH.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_metrics = pandas.read_csv(GBR_metrics_dataset_PATH.name)\n",
    "plot.figure(figsize=(16,9))\n",
    "plot.xlabel('Boosting Iterations')\n",
    "plot.ylabel('Deviance from Loss Funciton')\n",
    "for depth in gbr_metrics[\"max_depth\"].unique():\n",
    "    performance = gbr_metrics.where(gbr_metrics[\"max_depth\"] == depth).dropna()\n",
    "    plot.plot(performance[\"iteration\"], performance[\"training_loss\"], label = \"max_depth: \"  + str(depth))\n",
    "plot.legend(loc='upper right')\n",
    "plot.title(\"Metrics to select optimal parameters for GBR(Deviation vs Iteration for multiple Max_depth)\")\n",
    "plot.savefig(\"GBR_deviation_vs_iteration_for_multiple_max_depth.png\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html\n",
    "feature_importance = gradient_boosting_regressor.feature_importances_\n",
    "releative_feature_importance = (feature_importance / feature_importance.max()) * 100\n",
    "sorted_indices=numpy.argsort(releative_feature_importance)\n",
    "pos=numpy.arange(sorted_indices.shape[0])\n",
    "plot.barh(pos, releative_feature_importance[sorted_indices], align=\"center\")\n",
    "plot.yticks(pos, numpy.array(feature_names)[sorted_indices])\n",
    "plot.xlabel('Relative Importance')\n",
    "plot.title('Releative Feature Importance')\n",
    "plot.figure(figsize=(16, 9))\n",
    "plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
